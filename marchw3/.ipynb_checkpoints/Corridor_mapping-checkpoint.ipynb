{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named numarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-500da1786eb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlines\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLine2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpylab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnumarray\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Lets develop an EKF filter so that we can again estimate the collision points and use them as point landmarks. Later we can use\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named numarray"
     ]
    }
   ],
   "source": [
    "# Corridor Mapping\n",
    "\n",
    "%run Corridor_planning.ipynb                          # Ground truth\n",
    "\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Lets develop an EKF filter so that we can again estimate the collision points and use them as point landmarks. Later we can use\n",
    "# an SVM/RVM classifier to separate these points. But the only problem is that there are going to several points and we have to \n",
    "# use individual filters for each of them. Even though line representation can perform better in this way which we tried to avoid\n",
    "# in the above situation, we have to find a small cut through in this process. \n",
    "\n",
    "# Trajectory - Actual robot positions - Varialbe - xtraj and ytraj\n",
    "# Observations - collision angles - Variable - obs\n",
    "# Landmark positions - Variable - cor\n",
    "\n",
    "# Hit observations when x=-1 and x=1\n",
    "# Since we are trying yo do EKF, we directly obtain the absolute position of the landmarks as it is same as the robot position \n",
    "# at the instant of collision. Moreover, the mapping problem turns to be same as the localization problem.\n",
    "\n",
    "# On calculating robot's orientation from the global coordinate frame using the slope of the trajectory, subtract 90 degrees from\n",
    "# the slope to get the orientation in the global frame\n",
    "\n",
    "# Computing the collision angles in global and local coordinate frame\n",
    "# In the local coordinate frame (as in Corridor_trajectory), for the left corridor, the robot moves to the left and hence, dx <0\n",
    "# As a result, the collision angle is written in a shortcut form using the trajectory cor. See the diagram in rough\n",
    "# Computing the resulting collision observations in global coordinate frame, we have to convert from local coordinate frame to \n",
    "# global coordinate frame, and here it is equal to sum of robot's orientation in global coordinate frame and collision in local\n",
    "# coordinate frame. Remember that robot's orientation in local coordinate frame is 0.\n",
    "class corridor_mapping(object):\n",
    "    \"\"\" Corridor Mapping\n",
    "\n",
    "    Using the randomized robot trajectory, a map of the environment is built assuming the position of the robot is known with \n",
    "    certainty. This is a perfect mapping problem for the mobile robot, and this can be extended to SLAM problem provided the \n",
    "    model of the robot is known for using the motion model.\"\"\"    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.pose = np.matrix('0;0;0')\n",
    "        \n",
    "        self.distance = 0\n",
    "        self.landmarks = np.matrix('0,0,0')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    robot = corridor_mapping()                         # Initialize the robot\n",
    "    n = 0                                              # Number of landmarks\n",
    "    R = []\n",
    "    phi = []\n",
    "    ytraj_in = 0\n",
    "    xtraj_in = 0\n",
    "    \n",
    "    plt.figure(figsize=(12,12), dpi=100, facecolor = 'w')\n",
    "    plt.xlabel('X coordinates of the map',size=20)\n",
    "    plt.ylabel('Y coordinates of the map',size=20)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "    plt.title('Map of the corridor',size=20)\n",
    "    plt.xlim(-d/2-3,d/2+3)\n",
    "    plt.ylim(-4,cor.max()+2)\n",
    "    \n",
    "    for i in range(len(xtraj)):                        # Online estimator\n",
    "        #len(xtraj)\n",
    "        # Robot's prediction and odometry\n",
    "        # Robot's state is the pose of the robot and the added landmarks\n",
    "\n",
    "        robot.xest = np.vstack([xtraj[i], ytraj[i], np.arctan2(ytraj[i]- ytraj_in, xtraj[i] - xtraj_in) * 180/np.pi - 90]) \n",
    "        # Orientation in global coordinate frame\n",
    "        \n",
    "        # Robot's observation \n",
    "        if xtraj[i] == -d/2 or xtraj[i] == d/2:\n",
    "            \n",
    "            robot.landmarks = np.vstack([robot.landmarks,\n",
    "                                        np.hstack([xtraj[i], ytraj[i], \n",
    "                                                   np.arctan2(ytraj[i]-ytraj[i-1], xtraj[i] - xtraj[i-1])*180/np.pi - 90\n",
    "                                                  + obs[n]])])   # Orientation in global coordinate frame\n",
    "            n = n + 1   \n",
    "                     \n",
    "        xtraj_in = xtraj[i]\n",
    "        ytraj_in = ytraj[i]\n",
    "    \n",
    "    robot.landmarks = robot.landmarks[1:,:]\n",
    "\n",
    "    cax = []\n",
    "    cay = []\n",
    "    cat = []\n",
    "    \n",
    "    for i in range(len(robot.landmarks)):\n",
    "\n",
    "        cax.append(robot.landmarks[i,0])\n",
    "        cay.append(robot.landmarks[i,1])\n",
    "        cat.append((robot.landmarks[i,2]+90)*np.pi/180)\n",
    "\n",
    "        line = plt.Line2D((cax[i] - 0.5 * np.cos(cat[i]), cax[i] + 0.5 * np.cos(cat[i])), \n",
    "                          (cay[i] - 0.5 * np.sin(cat[i]), cay[i] + 0.5 * np.sin(cat[i])) , lw=2.5)\n",
    "\n",
    "        plt.gca().add_line(line)\n",
    "        plt.plot(cax[i],cay[i], 'ro', markersize=5, alpha=0.7)\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.123233995736766e-17"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cos(90*np.pi/180)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
