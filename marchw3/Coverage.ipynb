{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLAMming with Spheros\n",
    "=====\n",
    "\n",
    "##### IPython Notebook\n",
    "\n",
    "The complete GitHub repository is available at [Coverage](https://github.com/srinivaskandasamy/Coverage/tree/master/marchw3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weekly Report\n",
    "====\n",
    "***\n",
    "\n",
    "Monday, March $16^{th}$, 2015\n",
    "----\n",
    "\n",
    "### Meeting with Tamas\n",
    "\n",
    "1. Housing for Spheros\n",
    "   - Cannot open the new drawer\n",
    "   - To be replaced with a working one\n",
    "2. New version of the progress or coverage report looks better\n",
    "3. Conic estimation techniques\n",
    "   - Find out the possibilities of a conic probability distribution (less importance)\n",
    "   - Low dimensional approximation of distribution at the expense of direct incorporation of constraints\n",
    "   - Need to check the suitability of above from a corridor to a maze\n",
    "4. Installation of new video card to the new GPU machine (TUD0035314)\n",
    "   - Reference from Mazo\n",
    "   - GPU coding primer from Mazo (on CUDA)\n",
    "5. ETHZ Application to wait for few more days \n",
    "\n",
    "### Sphero trajectory creation\n",
    "\n",
    "1. Created a sample robot trajectory that has been sampled from a notmal gaussian over the inelastic collision angles\n",
    "2. Inelastic collision angles converted to variation in consecutive collision width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python code for inelastic collision trajectory in a corridor\n",
    "%run corridor_trajectory.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuesday, March $17^{th}$, 2015\n",
    "----\n",
    "\n",
    "### Difficulties related to impact-SLAM\n",
    "\n",
    "1. Particle filter-SLAM cannot be used due to the curse of dimensionality. However, the structure has been exploited to the most to reduce the growth of complexity in the system as in the literature. As in the state-of-the-art version of particle filter-SLAM, the localization problem was taken care by the Monte Carlo filters while the mapping problem was solved using EKF/UKF.\n",
    "2. In the case of impact based-SLAM, the presence of hard constraints makes it hard to approximate the probability density as a Gaussian. \n",
    "3. The estimators that comes to mind when hard constraints are present are particle filter and histogram filter, which can represent arbitrary distributions.\n",
    "4. The problem of localization in the existing particle filter-SLAM can be taken to be solved due to the arbitrary representation from Monte Carlo filters. Still mapping assumes the uncertainty as Gaussian. \n",
    "5. This leaves me back to the starting point of the problem - How to do impact-based online SLAM?\n",
    "\n",
    "### Corridor Mapping\n",
    "1. A suitable representation of the corridor\n",
    "   - Line representation in polar form (suffers from nonlinear transformation for parallel corridors - can be solved using unscented transform) \n",
    "   - Indistinct landmark representation, that is not suitable for EKF/UKF-SLAM\n",
    "   - Discontinuous line representation (looks novel)\n",
    "       - Most suitable for impact based representation\n",
    "       - Suitable for planning to actively avoid the hypotheses\n",
    "       - a maximum likelihood approach to avoid curse of dimensionality in finding and eliminating active hypotheses (consider the use of width of corridor to remove the blow-up in hypothese tree)\n",
    "       - Suitable for SLAM problem in a maze\n",
    "   - A SVM approach to map the corridor rather than building the entire corridor, and is more efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Tamas' view\n",
    "\n",
    "> As we discussed in the last meeting over the low dimensional version of estimation techniques, on using the hierarchical prior -corridor width, we reduced the dimension of landmark estimation from 2D to 1D. This can avoid the discontinuous probability distribution over higher dimension (2D). However, as pointed by you about the discontinuity in 1D in the case of robot colliding at the end of the wall, I do think that there exists active techniques to reduce this erroneous hypothesis at the end of a wall to a Gaussian of lower covariance by planning and with the expense of the strong hierarchical prior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wednesday, March $18^{th}$, 2015\n",
    "----\n",
    "\n",
    "### Corridor Mapping\n",
    "1. Generating the trajectory of the robot from the above randomized path selection\n",
    "2. Producing the collision data vector in the local coordinate frame of the robot\n",
    "3. Study of angle transformation between the local coordinate frame of the robot and global coordinate frame of the map or the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python code for path generation and observations in local coordinate frame of the robot\n",
    "%run corridor_planning.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thursday, March $19^{th}$, 2015\n",
    "----\n",
    "\n",
    "### Corridor Mapping\n",
    "1. Computing the collision angles in global and local coordinate frame\n",
    "2. Collisions are generated assuming that the user knows the corridor shape prior\n",
    "3. A simple low pass filter is used for generating the map of the corridor\n",
    "4. The observations are less corrupted, that is they are corrupted only due to numerical errors in the transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python code for corridor ampping\n",
    "# help(corridor_mapping)\n",
    "%run corridor_mapping.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Friday, March $20^{th}$, 2015\n",
    "----\n",
    "\n",
    "### Corridor Mapping\n",
    "1. Collected data points and executed low level planning\n",
    "2. A smoother approach to planning needs to be adopted to avoid rapid change in angle of incidence after obtuse angles of collision\n",
    "3. The code can be executed using the following command below and requires a Sphero.\n",
    "4. Streaming issues on editing the Sphero driver file (No clue where it appears from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python code for corridor mapping with a simple low level plannning\n",
    "%run corridor_temp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuesday, March $24^{th}$, 2015\n",
    "----\n",
    "\n",
    "### Corridor Mapping\n",
    "1. Started to experience a lot of issues with the Sphero driver methods\n",
    "2. Experienced common bluetooth issues with Sphero RBR (Need to verify in ROS)\n",
    "3. In the collision data, out of 10 collision detection, 2-3 are falsely detected and results in a different motion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generic mention\n",
    "--\n",
    "\n",
    "- Lagging behind the schedule currently by 4 days\n",
    "- Using occupancy grids for mapping since,\n",
    "- Vertex mapping and line based mapping produces a hypothesis tree which grows exponentially\n",
    "- Checking for better collision detection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"../styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
